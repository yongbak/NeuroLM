"""
í…ŒìŠ¤íŠ¸ìš© ê°€ì§œ EEG ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸
"""

import numpy as np
import pickle
import os
from pathlib import Path

# í‘œì¤€ 10-20 ì±„ë„ (ì‹¤ì œ EEG ì±„ë„ëª…)
standard_channels = [
    'FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',
    'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'FZ', 'CZ', 'PZ'
]

def create_dummy_eeg_data(n_channels=19, duration_sec=40, sampling_rate=200):
    """
    ê°€ì§œ EEG ë°ì´í„° ìƒì„±
    
    Args:
        n_channels: ì±„ë„ ìˆ˜ (ê¸°ë³¸ 19ê°œ)
        duration_sec: ê¸¸ì´ (ì´ˆ)
        sampling_rate: ìƒ˜í”Œë§ ë ˆì´íŠ¸ (Hz)
    
    Returns:
        eeg_data: (n_channels, n_samples) í˜•íƒœì˜ EEG ë°ì´í„°
        ch_names: ì±„ë„ëª… ë¦¬ìŠ¤íŠ¸
    """
    n_samples = duration_sec * sampling_rate
    
    # ì‹¤ì œ EEGì™€ ë¹„ìŠ·í•œ íŠ¹ì„±ì„ ê°€ì§„ ì‹ í˜¸ ìƒì„±
    eeg_data = np.zeros((n_channels, n_samples))
    
    for ch in range(n_channels):
        # 1. ê¸°ë³¸ ì£¼íŒŒìˆ˜ ì„±ë¶„ë“¤ (ì•ŒíŒŒíŒŒ, ë² íƒ€íŒŒ ë“±)
        time = np.linspace(0, duration_sec, n_samples)
        
        # ì•ŒíŒŒíŒŒ (8-12Hz) - ì£¼ë¡œ í›„ë‘ë¶€
        alpha = 10 * np.sin(2 * np.pi * 10 * time) if ch >= 8 else 5 * np.sin(2 * np.pi * 10 * time)
        
        # ë² íƒ€íŒŒ (13-30Hz) - ì£¼ë¡œ ì „ë‘ë¶€
        beta = 5 * np.sin(2 * np.pi * 20 * time) if ch < 8 else 2 * np.sin(2 * np.pi * 20 * time)
        
        # ì„¸íƒ€íŒŒ (4-8Hz)
        theta = 3 * np.sin(2 * np.pi * 6 * time)
        
        # ë¸íƒ€íŒŒ (0.5-4Hz)
        delta = 2 * np.sin(2 * np.pi * 2 * time)
        
        # 2. ë°±ìƒ‰ ì¡ìŒ
        noise = np.random.normal(0, 5, n_samples)
        
        # 3. 1/f ì¡ìŒ (ë” í˜„ì‹¤ì ì¸ EEG)
        freqs = np.fft.fftfreq(n_samples, 1/sampling_rate)
        freqs[0] = 1  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
        psd = 1 / np.abs(freqs)  # 1/f íŠ¹ì„±
        phase = np.random.uniform(-np.pi, np.pi, len(freqs))
        complex_noise = np.sqrt(psd) * np.exp(1j * phase)
        pink_noise = np.real(np.fft.ifft(complex_noise)) * 10
        
        # ëª¨ë“  ì„±ë¶„ í•©ì„±
        signal = alpha + beta + theta + delta + noise + pink_noise
        
        # Î¼V ë‹¨ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§ (ì¼ë°˜ì ì¸ EEG ë²”ìœ„: -100 ~ +100 Î¼V)
        signal = signal * 5  # ì•½ -50 ~ +50 Î¼V ë²”ìœ„
        
        eeg_data[ch] = signal
    
    # ì±„ë„ëª… ìƒì„±
    ch_names = standard_channels[:n_channels]
    
    return eeg_data, ch_names

def create_dummy_dataset(output_dir, n_files=10, train_ratio=0.8):
    """
    ì—¬ëŸ¬ ê°œì˜ ê°€ì§œ EEG íŒŒì¼ ìƒì„±
    
    Args:
        output_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬
        n_files: ìƒì„±í•  íŒŒì¼ ìˆ˜
        train_ratio: í›ˆë ¨/ê²€ì¦ ë¹„ìœ¨
    """
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    train_dir = Path(output_dir) / 'train'
    val_dir = Path(output_dir) / 'val'
    train_dir.mkdir(parents=True, exist_ok=True)
    val_dir.mkdir(parents=True, exist_ok=True)
    
    n_train = int(n_files * train_ratio)
    n_val = n_files - n_train
    
    print(f"Creating {n_train} training files and {n_val} validation files...")
    
    # í›ˆë ¨ ë°ì´í„° ìƒì„±
    for i in range(n_train):
        # ëœë¤í•œ íŠ¹ì„±ì˜ EEG ë°ì´í„° ìƒì„±
        n_channels = np.random.randint(16, 22)  # 16-21 ì±„ë„
        duration = np.random.randint(30, 60)    # 30-60ì´ˆ
        
        eeg_data, ch_names = create_dummy_eeg_data(
            n_channels=n_channels, 
            duration_sec=duration
        )
        
        # NeuroLM í˜•ì‹ìœ¼ë¡œ ì €ì¥
        data_dict = {
            "X": eeg_data,
            "ch_names": ch_names
        }
        
        file_path = train_dir / f"dummy_eeg_{i:04d}.pkl"
        with open(file_path, 'wb') as f:
            pickle.dump(data_dict, f)
        
        if i % 10 == 0:
            print(f"Created training file {i+1}/{n_train}")
    
    # ê²€ì¦ ë°ì´í„° ìƒì„±
    for i in range(n_val):
        n_channels = np.random.randint(16, 22)
        duration = np.random.randint(30, 60)
        
        eeg_data, ch_names = create_dummy_eeg_data(
            n_channels=n_channels, 
            duration_sec=duration
        )
        
        data_dict = {
            "X": eeg_data,
            "ch_names": ch_names
        }
        
        file_path = val_dir / f"dummy_eeg_val_{i:04d}.pkl"
        with open(file_path, 'wb') as f:
            pickle.dump(data_dict, f)
    
    print(f"âœ… Dataset created successfully!")
    print(f"ğŸ“ Training files: {train_dir}")
    print(f"ğŸ“ Validation files: {val_dir}")
    print(f"ğŸ“Š Total files: {n_files}")

def create_text_data(output_dir):
    """
    í…ìŠ¤íŠ¸ ë°ì´í„°ë„ ìƒì„± (train_pretrain.pyìš©)
    """
    text_dir = Path(output_dir) / 'text'
    text_dir.mkdir(parents=True, exist_ok=True)
    
    # ê°„ë‹¨í•œ ë”ë¯¸ í…ìŠ¤íŠ¸ ë°ì´í„°
    vocab_size = 50257  # GPT-2 vocab size
    sequence_length = 100000
    
    # í›ˆë ¨ìš©
    train_data = np.random.randint(0, vocab_size, sequence_length, dtype=np.uint16)
    train_path = text_dir / 'train.bin'
    train_data.tofile(train_path)
    
    # ê²€ì¦ìš©
    val_data = np.random.randint(0, vocab_size, sequence_length // 10, dtype=np.uint16)
    val_path = text_dir / 'val.bin'
    val_data.tofile(val_path)
    
    print(f"ğŸ“ Text data created: {text_dir}")

if __name__ == "__main__":
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    output_dir = "../dummy_dataset"
    
    # ë°ì´í„°ì…‹ ìƒì„±
    create_dummy_dataset(output_dir, n_files=50)  # 50ê°œ íŒŒì¼ ìƒì„±
    create_text_data(output_dir)  # í…ìŠ¤íŠ¸ ë°ì´í„°ë„ ìƒì„±
    
    print("\nğŸ‰ Dummy dataset creation completed!")
    print(f"\nì‚¬ìš©ë²•:")
    print(f"python train_vq.py --dataset_dir {output_dir}")
